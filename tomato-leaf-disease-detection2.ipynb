{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries for Image Classification Pipeline\n",
    "#\n",
    "# This cell imports all necessary libraries and modules for:\n",
    "# - Loading, processing, and augmenting images\n",
    "# - Building a Convolutional Neural Network (CNN) using Keras\n",
    "# - Preprocessing labels for multi-class or multi-label classification\n",
    "# - Splitting the dataset into training and test sets\n",
    "# - Visualizing results\n",
    "\n",
    "import numpy as np\n",
    "import pickle  \n",
    "import cv2 \n",
    "from os import listdir \n",
    "\n",
    "# Preprocessing and encoding\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer  \n",
    "\n",
    "# Keras deep learning imports\n",
    "from keras.models import Sequential  \n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense \n",
    "from keras import backend as K  \n",
    "\n",
    "# Keras utilities for preprocessing images\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.optimizers import Adam  \n",
    "from keras.preprocessing import image   \n",
    "from keras.preprocessing.image import img_to_array \n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Matplotlib for plotting\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8086c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Configuration Constants for Model Training and Image Processing\n",
    "#\n",
    "# This cell sets up:\n",
    "# - Model hyperparameters\n",
    "# - Default image dimensions\n",
    "# - Dataset directory location\n",
    "\n",
    "\n",
    "EPOCHS = 25\n",
    "# int: Number of epochs (full passes through the training data) during model training.\n",
    "\n",
    "INIT_LR = 1e-3\n",
    "# float: Initial learning rate for the optimizer (Adam). Controls how quickly the model updates weights.\n",
    "\n",
    "BS = 32\n",
    "# int: Batch size. Number of images processed before updating model weights.\n",
    "\n",
    "default_image_size = tuple((256, 256))\n",
    "\n",
    "\n",
    "image_size = 0\n",
    "# int: Placeholder variable for image size (not yet set). May be used later for dynamic resizing.\n",
    "\n",
    "directory_root = '../input/plantvillage/'\n",
    "# str: Path to the root directory containing the dataset of images.\n",
    "\n",
    "width = 256\n",
    "# int: Target image width in pixels.\n",
    "\n",
    "height = 256\n",
    "# int: Target image height in pixels.\n",
    "\n",
    "depth = 3\n",
    "# int: Number of color channels in the input images (3 for RGB).\n",
    "  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to hold image data and their corresponding labels\n",
    "image_list, label_list = [], []\n",
    "\n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "\n",
    "    # List all folders in the root directory (e.g., plant types)\n",
    "    root_dir = listdir(directory_root)\n",
    "\n",
    "    # Remove macOS system file if present\n",
    "    for directory in root_dir:\n",
    "        if directory == \".DS_Store\":\n",
    "            root_dir.remove(directory)\n",
    "\n",
    "    # Loop through each plant category folder\n",
    "    for plant_folder in root_dir:\n",
    "        # List all disease-specific folders inside each plant category\n",
    "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
    "\n",
    "        # Remove .DS_Store from disease folders\n",
    "        for disease_folder in plant_disease_folder_list:\n",
    "            if disease_folder == \".DS_Store\":\n",
    "                plant_disease_folder_list.remove(disease_folder)\n",
    "\n",
    "        # Loop through each plant disease folder\n",
    "        for plant_disease_folder in plant_disease_folder_list:\n",
    "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
    "\n",
    "            # Get list of image files in the disease folder\n",
    "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
    "\n",
    "            # Remove .DS_Store if present in the image list\n",
    "            for single_plant_disease_image in plant_disease_image_list:\n",
    "                if single_plant_disease_image == \".DS_Store\":\n",
    "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
    "\n",
    "            # Limit to first 200 images (can help manage dataset size during testing/training)\n",
    "            for image in plant_disease_image_list[:200]:\n",
    "                # Build the complete path to the image file\n",
    "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
    "\n",
    "                # Only process JPG files\n",
    "                if image_directory.endswith(\".jpg\") or image_directory.endswith(\".JPG\"):\n",
    "                    # Convert image to array and add to list\n",
    "                    image_array = convert_image_to_array(image_directory)\n",
    "                    image_list.append(image_array)\n",
    "\n",
    "                    # Append corresponding label (disease folder name)\n",
    "                    label_list.append(plant_disease_folder)\n",
    "\n",
    "    print(\"[INFO] Image loading completed\")  \n",
    "\n",
    "except Exception as e:\n",
    "    # Catch and print any error that occurs during loading\n",
    "    print(f\"Error : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d39090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelBinarizer to convert string labels into one-hot encoded vectors\n",
    "label_binarizer = LabelBinarizer()\n",
    "\n",
    "# Fit the label binarizer on the collected labels and transform them into one-hot encoded format\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "\n",
    "# Save the fitted label binarizer to a file so it can be reused later (e.g., during inference)\n",
    "pickle.dump(label_binarizer, open('label_transform.pkl', 'wb'))\n",
    "\n",
    "# Get the total number of unique classes (i.e., plant diseases)\n",
    "n_classes = len(label_binarizer.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Image List to NumPy Array and Normalize\n",
    "\n",
    "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data into Training and Testing Sets\n",
    "\n",
    "print(\"[INFO] Spliting data to train, test\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56042f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Setup\n",
    "#\n",
    "# This cell configures an ImageDataGenerator to perform real-time data augmentation.\n",
    "# Augmentation helps improve model generalization by creating varied versions\n",
    "# of the training images.\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, \n",
    "    zoom_range=0.2,horizontal_flip=True, \n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Convolutional Neural Network (CNN) Model\n",
    "#\n",
    "# This block defines a Sequential CNN architecture for image classification.\n",
    "# It includes:\n",
    "# - Multiple convolutional layers to extract spatial features\n",
    "# - Batch normalization to stabilize learning\n",
    "# - Max pooling to downsample feature maps\n",
    "# - Dropout to reduce overfitting\n",
    "# - Dense layers for final classification\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "inputShape = (height, width, depth)\n",
    "chanDim = -1\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    inputShape = (depth, height, width)\n",
    "    chanDim = 1\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b832ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "# distribution\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258992c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the CNN Model with Data Augmentation\n",
    "#\n",
    "# This cell fits the model using the augmented image generator.\n",
    "# The generator yields batches of augmented data in real time.\n",
    "# Training progress and validation performance are stored in `history`.\n",
    "\n",
    "history = model.fit_generator(\n",
    "    aug.flow(x_train, y_train, batch_size=BS),\n",
    "    validation_data=(x_test, y_test),\n",
    "    steps_per_epoch=len(x_train) // BS,\n",
    "    epochs=EPOCHS, verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "#Train and validation accuracy\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d360252",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Calculating model accuracy\")\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {scores[1]*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
